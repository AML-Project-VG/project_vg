2022-01-14 16:49:10   Arguments: Namespace(backbone='resnet18', cache_refresh_rate=1000, datasets_folder='./Dataset_pitts30k', device='cuda', epochs_num=20, exp_name='default', gem_eps=1e-06, gem_p=3, infer_batch_size=16, lr=0.0001, margin=0.1, momentum=0.9, neg_samples_num=1000, negs_num_per_query=10, netvlad_clusters=64, num_workers=8, output_folder='runs/default/2022-01-14_16-49-10', patience=3, queries_per_epoch=5000, recall_values=[1, 5, 10, 20], seed=0, test_dataset_name=None, test_model_path=None, train_batch_size=4, train_positives_dist_threshold=10, use_adagrad=None, use_gem=None, use_netvlad=True, use_sgd=None, val_positive_dist_threshold=25)
2022-01-14 16:49:10   The outputs are being saved in runs/default/2022-01-14_16-49-10
2022-01-14 16:49:10   Using 1 GPUs and 2 CPUs
2022-01-14 16:49:10   There are 96 queries without any positives within the training set. They won't be considered as they're useless for training.
2022-01-14 16:49:10   Train query set: < TripletsDataset, pitts30k - #database: 10000; #queries: 7320 >
2022-01-14 16:49:11   Val set: < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >
2022-01-14 16:49:11   Test set: < BaseDataset, pitts30k - #database: 10000; #queries: 6816 >
2022-01-14 16:49:14   Output dimension of the model is 16384
2022-01-14 16:49:14   Start training epoch: 00
2022-01-14 17:21:19   Finished epoch 00 in 0:32:04, average epoch triplet loss = 0.0154
2022-01-14 17:25:14   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 87.1, R@5: 95.3, R@10: 96.9, R@20: 98.1
2022-01-14 17:25:14   Improved: previous best R@5 = 0.0, current R@5 = 95.3
2022-01-14 17:25:14   Start training epoch: 01
2022-01-14 18:00:12   Finished epoch 01 in 0:34:57, average epoch triplet loss = 0.0088
2022-01-14 18:04:11   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 87.5, R@5: 95.5, R@10: 97.3, R@20: 98.4
2022-01-14 18:04:12   Improved: previous best R@5 = 95.3, current R@5 = 95.5
2022-01-14 18:04:12   Start training epoch: 02
2022-01-14 18:38:55   Finished epoch 02 in 0:34:43, average epoch triplet loss = 0.0066
2022-01-14 18:42:54   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 87.6, R@5: 95.4, R@10: 97.2, R@20: 98.3
2022-01-14 18:42:54   Not improved: 1 / 3: best R@5 = 95.5, current R@5 = 95.4
2022-01-14 18:42:54   Start training epoch: 03
2022-01-14 19:19:55   Finished epoch 03 in 0:37:00, average epoch triplet loss = 0.0058
2022-01-14 19:23:58   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 87.4, R@5: 95.9, R@10: 97.4, R@20: 98.3
2022-01-14 19:23:59   Improved: previous best R@5 = 95.5, current R@5 = 95.9
2022-01-14 19:23:59   Start training epoch: 04
2022-01-14 19:58:57   Finished epoch 04 in 0:34:58, average epoch triplet loss = 0.0054
2022-01-14 20:02:51   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 87.9, R@5: 95.4, R@10: 97.2, R@20: 98.3
2022-01-14 20:02:52   Not improved: 1 / 3: best R@5 = 95.9, current R@5 = 95.4
2022-01-14 20:02:52   Start training epoch: 05
2022-01-14 20:40:02   Finished epoch 05 in 0:37:09, average epoch triplet loss = 0.0053
2022-01-14 20:44:00   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 87.5, R@5: 95.4, R@10: 97.2, R@20: 98.4
2022-01-14 20:44:01   Not improved: 2 / 3: best R@5 = 95.9, current R@5 = 95.4
2022-01-14 20:44:01   Start training epoch: 06
2022-01-14 21:20:09   Finished epoch 06 in 0:36:07, average epoch triplet loss = 0.0049
2022-01-14 21:24:12   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 87.4, R@5: 95.3, R@10: 97.1, R@20: 98.3
2022-01-14 21:24:13   Not improved: 3 / 3: best R@5 = 95.9, current R@5 = 95.3
2022-01-14 21:24:13   Performance did not improve for 3 epochs. Stop training.
2022-01-14 21:24:13   Best R@5: 95.9
2022-01-14 21:24:13   Trained for 07 epochs, in total in 4:35:03
2022-01-14 21:31:34   Recalls on < BaseDataset, pitts30k - #database: 10000; #queries: 6816 >: R@1: 84.1, R@5: 91.9, R@10: 94.2, R@20: 96.0