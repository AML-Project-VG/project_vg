2022-01-08 18:40:32   Arguments: Namespace(use_netvlad=None, netvlad_clusters=64, use_gem=True, gem_p=3, gem_eps=1e-06, train_batch_size=4, infer_batch_size=16, margin=0.1, epochs_num=5, patience=3, lr=0.0001, cache_refresh_rate=1000, queries_per_epoch=5000, negs_num_per_query=10, neg_samples_num=1000, seed=0, device='cuda', num_workers=8, val_positive_dist_threshold=25, train_positives_dist_threshold=10, recall_values=[1, 5, 10, 20], datasets_folder='./Data', exp_name='default', output_folder='runs/default/2022-01-08_18-40-32')
2022-01-08 18:40:32   The outputs are being saved in runs/default/2022-01-08_18-40-32
2022-01-08 18:40:32   Using 1 GPUs and 12 CPUs
2022-01-08 18:40:32   Loading dataset Pitts30k from folder ./Data
2022-01-08 18:40:32   There are 96 queries without any positives within the training set. They won't be considered as they're useless for training.
2022-01-08 18:40:32   Train query set: < TripletsDataset, pitts30k - #database: 10000; #queries: 7320 >
2022-01-08 18:40:33   Val set: < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >
2022-01-08 18:40:33   Test set: < BaseDataset, pitts30k - #database: 10000; #queries: 6816 >
2022-01-08 18:40:33   Train only conv4 of the ResNet-18 (remove conv5), freeze the previous ones
2022-01-08 18:40:38   Output dimension of the model is 256
2022-01-08 18:40:38   Start training epoch: 00
2022-01-08 18:40:38   Cache: 0 / 5
2022-01-08 18:41:55   Epoch[00](0/5): current batch triplet loss = 0.0649, average epoch triplet loss = 0.0558
2022-01-08 18:41:55   Cache: 1 / 5
2022-01-08 18:43:12   Epoch[00](1/5): current batch triplet loss = 0.0435, average epoch triplet loss = 0.0522
2022-01-08 18:43:12   Cache: 2 / 5
2022-01-08 18:44:32   Epoch[00](2/5): current batch triplet loss = 0.0251, average epoch triplet loss = 0.0475
2022-01-08 18:44:32   Cache: 3 / 5
2022-01-08 18:45:50   Epoch[00](3/5): current batch triplet loss = 0.0517, average epoch triplet loss = 0.0444
2022-01-08 18:45:50   Cache: 4 / 5
2022-01-08 18:47:08   Epoch[00](4/5): current batch triplet loss = 0.0535, average epoch triplet loss = 0.0421
2022-01-08 18:47:08   Finished epoch 00 in 0:06:30, average epoch triplet loss = 0.0421
2022-01-08 18:47:08   Extracting database features for evaluation/testing
2022-01-08 18:47:35   Extracting queries features for evaluation/testing
2022-01-08 18:47:56   Calculating recalls
2022-01-08 18:47:57   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 57.5, R@5: 77.9, R@10: 85.1, R@20: 90.6
2022-01-08 18:47:57   Improved: previous best R@5 = 0.0, current R@5 = 77.9
2022-01-08 18:47:57   Start training epoch: 01
2022-01-08 18:47:57   Cache: 0 / 5
2022-01-08 18:49:15   Epoch[01](0/5): current batch triplet loss = 0.0317, average epoch triplet loss = 0.0309
2022-01-08 18:49:15   Cache: 1 / 5
2022-01-08 18:50:33   Epoch[01](1/5): current batch triplet loss = 0.0187, average epoch triplet loss = 0.0290
2022-01-08 18:50:33   Cache: 2 / 5
2022-01-08 18:51:51   Epoch[01](2/5): current batch triplet loss = 0.0254, average epoch triplet loss = 0.0274
2022-01-08 18:51:51   Cache: 3 / 5
2022-01-08 18:53:10   Epoch[01](3/5): current batch triplet loss = 0.0388, average epoch triplet loss = 0.0270
2022-01-08 18:53:10   Cache: 4 / 5
2022-01-08 18:54:28   Epoch[01](4/5): current batch triplet loss = 0.0244, average epoch triplet loss = 0.0263
2022-01-08 18:54:28   Finished epoch 01 in 0:06:31, average epoch triplet loss = 0.0263
2022-01-08 18:54:28   Extracting database features for evaluation/testing
2022-01-08 18:54:55   Extracting queries features for evaluation/testing
2022-01-08 18:55:15   Calculating recalls
2022-01-08 18:55:16   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 58.1, R@5: 79.2, R@10: 86.1, R@20: 91.7
2022-01-08 18:55:17   Improved: previous best R@5 = 77.9, current R@5 = 79.2
2022-01-08 18:55:17   Start training epoch: 02
2022-01-08 18:55:17   Cache: 0 / 5
2022-01-08 18:56:35   Epoch[02](0/5): current batch triplet loss = 0.0189, average epoch triplet loss = 0.0207
2022-01-08 18:56:35   Cache: 1 / 5
2022-01-08 18:57:53   Epoch[02](1/5): current batch triplet loss = 0.0191, average epoch triplet loss = 0.0205
2022-01-08 18:57:53   Cache: 2 / 5
2022-01-08 18:59:12   Epoch[02](2/5): current batch triplet loss = 0.0035, average epoch triplet loss = 0.0200
2022-01-08 18:59:12   Cache: 3 / 5
2022-01-08 19:00:33   Epoch[02](3/5): current batch triplet loss = 0.0254, average epoch triplet loss = 0.0194
2022-01-08 19:00:33   Cache: 4 / 5
2022-01-08 19:01:52   Epoch[02](4/5): current batch triplet loss = 0.0048, average epoch triplet loss = 0.0192
2022-01-08 19:01:52   Finished epoch 02 in 0:06:35, average epoch triplet loss = 0.0192
2022-01-08 19:01:52   Extracting database features for evaluation/testing
2022-01-08 19:02:19   Extracting queries features for evaluation/testing
2022-01-08 19:02:40   Calculating recalls
2022-01-08 19:02:41   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 56.3, R@5: 78.6, R@10: 85.4, R@20: 90.1
2022-01-08 19:02:41   Not improved: 1 / 3: best R@5 = 79.2, current R@5 = 78.6
2022-01-08 19:02:41   Start training epoch: 03
2022-01-08 19:02:41   Cache: 0 / 5
2022-01-08 19:04:00   Epoch[03](0/5): current batch triplet loss = 0.0072, average epoch triplet loss = 0.0164
2022-01-08 19:04:00   Cache: 1 / 5
2022-01-08 19:05:20   Epoch[03](1/5): current batch triplet loss = 0.0161, average epoch triplet loss = 0.0172
2022-01-08 19:05:20   Cache: 2 / 5
2022-01-08 19:06:40   Epoch[03](2/5): current batch triplet loss = 0.0108, average epoch triplet loss = 0.0169
2022-01-08 19:06:40   Cache: 3 / 5
2022-01-08 19:07:58   Epoch[03](3/5): current batch triplet loss = 0.0288, average epoch triplet loss = 0.0167
2022-01-08 19:07:58   Cache: 4 / 5
2022-01-08 19:09:14   Epoch[03](4/5): current batch triplet loss = 0.0147, average epoch triplet loss = 0.0163
2022-01-08 19:09:14   Finished epoch 03 in 0:06:33, average epoch triplet loss = 0.0163
2022-01-08 19:09:14   Extracting database features for evaluation/testing
2022-01-08 19:09:40   Extracting queries features for evaluation/testing
2022-01-08 19:10:01   Calculating recalls
2022-01-08 19:10:02   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 56.8, R@5: 78.8, R@10: 85.0, R@20: 90.5
2022-01-08 19:10:02   Not improved: 2 / 3: best R@5 = 79.2, current R@5 = 78.8
2022-01-08 19:10:02   Start training epoch: 04
2022-01-08 19:10:02   Cache: 0 / 5
2022-01-08 19:11:18   Epoch[04](0/5): current batch triplet loss = 0.0012, average epoch triplet loss = 0.0160
2022-01-08 19:11:18   Cache: 1 / 5
2022-01-08 19:12:33   Epoch[04](1/5): current batch triplet loss = 0.0063, average epoch triplet loss = 0.0155
2022-01-08 19:12:33   Cache: 2 / 5
2022-01-08 19:13:53   Epoch[04](2/5): current batch triplet loss = 0.0378, average epoch triplet loss = 0.0154
2022-01-08 19:13:53   Cache: 3 / 5
2022-01-08 19:15:12   Epoch[04](3/5): current batch triplet loss = 0.0116, average epoch triplet loss = 0.0154
2022-01-08 19:15:12   Cache: 4 / 5
2022-01-08 19:16:32   Epoch[04](4/5): current batch triplet loss = 0.0033, average epoch triplet loss = 0.0150
2022-01-08 19:16:32   Finished epoch 04 in 0:06:29, average epoch triplet loss = 0.0150
2022-01-08 19:16:32   Extracting database features for evaluation/testing
2022-01-08 19:17:00   Extracting queries features for evaluation/testing
2022-01-08 19:17:21   Calculating recalls
2022-01-08 19:17:22   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 55.7, R@5: 77.8, R@10: 85.3, R@20: 90.0
2022-01-08 19:17:23   Not improved: 3 / 3: best R@5 = 79.2, current R@5 = 77.8
2022-01-08 19:17:23   Performance did not improve for 3 epochs. Stop training.
2022-01-08 19:17:23   Best R@5: 79.2
2022-01-08 19:17:23   Trained for 05 epochs, in total in 0:36:50
2022-01-08 19:17:23   Extracting database features for evaluation/testing
2022-01-08 19:17:50   Extracting queries features for evaluation/testing
2022-01-08 19:18:09   Calculating recalls
2022-01-08 19:18:10   Recalls on < BaseDataset, pitts30k - #database: 10000; #queries: 6816 >: R@1: 57.9, R@5: 79.4, R@10: 86.6, R@20: 91.4
