2022-01-19 16:23:37   Arguments: Namespace(upscale_input=False, downscale_input=False, augment_input='None', backbone='resnet18', use_netvlad=True, netvlad_clusters=64, use_gem=None, gem_p=3, gem_eps=1e-06, use_attention='cbam', attention_lr=0.001, use_sgd=None, use_adagrad=None, momentum=0.9, train_batch_size=4, infer_batch_size=16, margin=0.1, epochs_num=5, patience=3, lr=1e-05, cache_refresh_rate=1000, queries_per_epoch=5000, negs_num_per_query=10, neg_samples_num=1000, seed=0, device='cuda', num_workers=8, val_positive_dist_threshold=25, train_positives_dist_threshold=10, recall_values=[1, 5, 10, 20], datasets_folder='Dataset_pitts30k', exp_name='default', test_dataset_name='pitts30k', test_model_path='./Runs/netvlad_20_64_10e-5_adam_crn_0.001/best_model.pth', save_attention_mask=True, output_folder='test_runs/default/2022-01-19_16-23-37')
2022-01-19 16:23:37   The outputs are being saved in test_runs/default/2022-01-19_16-23-37
2022-01-19 16:23:37   Using 1 GPUs and 12 CPUs
2022-01-19 16:23:37   Loading test dataset pitts30k from folder Dataset_pitts30k
2022-01-19 16:23:37   Test set: < BaseDataset, pitts30k - #database: 10000; #queries: 6816 >
2022-01-19 16:23:37   Train only conv4 of the ResNet-18 (remove conv5), freeze the previous ones
2022-01-19 16:23:40   
Traceback (most recent call last):
  File "/home/franzhd/Aml_project/project_vg/run_test.py", line 44, in <module>
    model.load_state_dict(model_state_dict)
  File "/home/franzhd/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1482, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for GeoLocalizationNet:
	Missing key(s) in state_dict: "attention.ca.se.0.weight", "attention.ca.se.2.weight", "attention.sa.conv.weight", "attention.sa.conv.bias". 
	Unexpected key(s) in state_dict: "attention.conv3x3.0.weight", "attention.conv3x3.0.bias", "attention.conv5x5.0.weight", "attention.conv5x5.0.bias", "attention.conv7x7.0.weight", "attention.conv7x7.0.bias", "attention.convw.0.weight", "attention.convw.0.bias". 

