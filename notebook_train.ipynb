{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-17 12:09:40   Arguments: Namespace(upscale_input=False, downscale_input=False, augment_input='None', backbone='resnet50-conv4', use_netvlad=True, netvlad_clusters=64, use_gem=None, gem_p=3, gem_eps=1e-06, use_sgd=None, use_adagrad=None, momentum=0.9, train_batch_size=4, infer_batch_size=16, margin=0.1, epochs_num=20, patience=3, lr=1e-05, cache_refresh_rate=1000, queries_per_epoch=5000, negs_num_per_query=10, neg_samples_num=1000, seed=0, device='cuda', num_workers=12, val_positive_dist_threshold=25, train_positives_dist_threshold=10, recall_values=[1, 5, 10, 20], datasets_folder='./Dataset_pitts30k', exp_name='default', test_dataset_name=None, test_model_path=None, output_folder='runs/default/2022-01-17_12-09-40')\n",
      "2022-01-17 12:09:40   The outputs are being saved in runs/default/2022-01-17_12-09-40\n",
      "2022-01-17 12:09:40   Using 1 GPUs and 12 CPUs\n",
      "2022-01-17 12:09:40   Loading dataset Pitts30k from folder ./Dataset_pitts30k\n",
      "2022-01-17 12:09:40   There are 96 queries without any positives within the training set. They won't be considered as they're useless for training.\n",
      "/usr/lib/python3/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "2022-01-17 12:09:40   Train query set: < TripletsDataset, pitts30k - #database: 10000; #queries: 7320 >\n",
      "2022-01-17 12:09:40   Val set: < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >\n",
      "2022-01-17 12:09:40   Test set: < BaseDataset, pitts30k - #database: 10000; #queries: 6816 >\n",
      "2022-01-17 12:09:41   Cut conv5, Train only conv4 of the ResNet-50, freeze the previous ones\n",
      "2022-01-17 12:09:41   \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/franzhd/Aml_project/project_vg/run_train.py\", line 47, in <module>\n",
      "    model = network.GeoLocalizationNet(args)\n",
      "  File \"/home/franzhd/Aml_project/project_vg/network.py\", line 31, in __init__\n",
      "    with h5py.File(initcache, mode='r') as h5:\n",
      "  File \"/home/franzhd/.local/lib/python3.9/site-packages/h5py/_hl/files.py\", line 507, in __init__\n",
      "    fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr)\n",
      "  File \"/home/franzhd/.local/lib/python3.9/site-packages/h5py/_hl/files.py\", line 220, in make_fid\n",
      "    fid = h5f.open(name, flags, fapl=fapl)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5f.pyx\", line 106, in h5py.h5f.open\n",
      "FileNotFoundError: [Errno 2] Unable to open file (unable to open file: name = './Dataset_pitts30k/centroids_64_resnet50-conv4_desc_cen.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python3 run_train.py --num_workers 12 --datasets_folder ./Dataset_pitts30k --use_netvlad True --backbone resnet50-conv4 --lr 0.00001 --epoch 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 run_clustering.py --datasets_folder ./Dataset_pitts30k --backbone resnet50-conv4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-17 12:09:21   Arguments: Namespace(upscale_input=False, downscale_input=False, augment_input='None', backbone='resnet50moco-conv4', use_netvlad=True, netvlad_clusters=64, use_gem=None, gem_p=3, gem_eps=1e-06, use_sgd=None, use_adagrad=None, momentum=0.9, train_batch_size=4, infer_batch_size=16, margin=0.1, epochs_num=20, patience=3, lr=1e-05, cache_refresh_rate=1000, queries_per_epoch=5000, negs_num_per_query=10, neg_samples_num=1000, seed=0, device='cuda', num_workers=12, val_positive_dist_threshold=25, train_positives_dist_threshold=10, recall_values=[1, 5, 10, 20], datasets_folder='./Dataset_pitts30k', exp_name='default', test_dataset_name=None, test_model_path=None, output_folder='runs/default/2022-01-17_12-09-21')\n",
      "2022-01-17 12:09:21   The outputs are being saved in runs/default/2022-01-17_12-09-21\n",
      "2022-01-17 12:09:21   Using 1 GPUs and 12 CPUs\n",
      "2022-01-17 12:09:21   Loading dataset Pitts30k from folder ./Dataset_pitts30k\n",
      "2022-01-17 12:09:22   There are 96 queries without any positives within the training set. They won't be considered as they're useless for training.\n",
      "/usr/lib/python3/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "2022-01-17 12:09:22   Train query set: < TripletsDataset, pitts30k - #database: 10000; #queries: 7320 >\n",
      "2022-01-17 12:09:22   Val set: < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >\n",
      "2022-01-17 12:09:22   Test set: < BaseDataset, pitts30k - #database: 10000; #queries: 6816 >\n",
      "2022-01-17 12:09:22   \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/franzhd/Aml_project/project_vg/run_train.py\", line 47, in <module>\n",
      "    model = network.GeoLocalizationNet(args)\n",
      "  File \"/home/franzhd/Aml_project/project_vg/network.py\", line 20, in __init__\n",
      "    self.backbone = get_backbone(args)\n",
      "  File \"/home/franzhd/Aml_project/project_vg/network.py\", line 107, in get_backbone\n",
      "    backbone = torch.load('moco_v1_200ep_pretrain.pth.tar')\n",
      "  File \"/home/franzhd/.local/lib/python3.9/site-packages/torch/serialization.py\", line 594, in load\n",
      "    with _open_file_like(f, 'rb') as opened_file:\n",
      "  File \"/home/franzhd/.local/lib/python3.9/site-packages/torch/serialization.py\", line 230, in _open_file_like\n",
      "    return _open_file(name_or_buffer, mode)\n",
      "  File \"/home/franzhd/.local/lib/python3.9/site-packages/torch/serialization.py\", line 211, in __init__\n",
      "    super(_open_file, self).__init__(open(name, mode))\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'moco_v1_200ep_pretrain.pth.tar'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python3 run_train.py --num_workers 12 --datasets_folder ./Dataset_pitts30k --use_netvlad True --backbone resnet50moco-conv4 --lr 0.00001 --epoch 20"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
