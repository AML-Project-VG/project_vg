2022-01-20 12:21:31   Arguments: Namespace(upscale_input=False, downscale_input=False, augment_input='None', backbone='resnet18', use_netvlad=True, netvlad_clusters=64, use_gem=None, gem_p=3, gem_eps=1e-06, use_attention='cbam', attention_lr=0.01, use_sgd=None, use_adagrad=None, momentum=0.9, train_batch_size=4, infer_batch_size=16, margin=0.1, epochs_num=20, patience=3, lr=1e-05, cache_refresh_rate=1000, queries_per_epoch=5000, negs_num_per_query=10, neg_samples_num=1000, seed=0, device='cuda', num_workers=8, val_positive_dist_threshold=25, train_positives_dist_threshold=10, recall_values=[1, 5, 10, 20], datasets_folder='./Dataset_pitts30k', exp_name='default', test_dataset_name=None, test_model_path=None, save_attention_mask=None, output_folder='runs/default/2022-01-20_12-21-31')
2022-01-20 12:21:31   The outputs are being saved in runs/default/2022-01-20_12-21-31
2022-01-20 12:21:31   Using 1 GPUs and 12 CPUs
2022-01-20 12:21:31   There are 96 queries without any positives within the training set. They won't be considered as they're useless for training.
2022-01-20 12:21:31   Train query set: < TripletsDataset, pitts30k - #database: 10000; #queries: 7320 >
2022-01-20 12:21:31   Val set: < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >
2022-01-20 12:21:31   Test set: < BaseDataset, pitts30k - #database: 10000; #queries: 6816 >
2022-01-20 12:21:36   Output dimension of the model is 16384
2022-01-20 12:21:36   Start training epoch: 00
2022-01-20 12:27:32   
Traceback (most recent call last):
  File "/home/franzhd/Aml_project/project_vg/run_train.py", line 129, in <module>
    optimizer.step()
  File "/home/franzhd/.local/lib/python3.9/site-packages/torch/optim/optimizer.py", line 88, in wrapper
    return func(*args, **kwargs)
  File "/home/franzhd/.local/lib/python3.9/site-packages/torch/autograd/grad_mode.py", line 28, in decorate_context
    return func(*args, **kwargs)
  File "/home/franzhd/.local/lib/python3.9/site-packages/torch/optim/adam.py", line 133, in step
    F.adam(params_with_grad,
  File "/home/franzhd/.local/lib/python3.9/site-packages/torch/optim/_functional.py", line 94, in adam
    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)
KeyboardInterrupt

