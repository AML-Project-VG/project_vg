2022-01-18 17:19:40   Arguments: Namespace(upscale_input=False, downscale_input=True, augment_input='None', backbone='resnet18', use_netvlad=True, netvlad_clusters=64, use_gem=None, gem_p=3, gem_eps=1e-06, use_attention='crn', crn_lr=0.001, use_sgd=None, use_adagrad=None, momentum=0.9, train_batch_size=4, infer_batch_size=16, margin=0.1, epochs_num=20, patience=3, lr=1e-05, cache_refresh_rate=1000, queries_per_epoch=5000, negs_num_per_query=10, neg_samples_num=1000, seed=0, device='cuda', num_workers=8, val_positive_dist_threshold=25, train_positives_dist_threshold=10, recall_values=[1, 5, 10, 20], datasets_folder='./Dataset_pitts30k', exp_name='default', test_dataset_name=None, test_model_path=None, output_folder='runs/default/2022-01-18_17-19-40')
2022-01-18 17:19:40   The outputs are being saved in runs/default/2022-01-18_17-19-40
2022-01-18 17:19:40   Using 1 GPUs and 12 CPUs
2022-01-18 17:19:40   Loading dataset Pitts30k from folder ./Dataset_pitts30k
2022-01-18 17:19:41   There are 96 queries without any positives within the training set. They won't be considered as they're useless for training.
2022-01-18 17:19:41   Train query set: < TripletsDataset, pitts30k - #database: 10000; #queries: 7320 >
2022-01-18 17:19:41   Val set: < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >
2022-01-18 17:19:41   Test set: < BaseDataset, pitts30k - #database: 10000; #queries: 6816 >
2022-01-18 17:19:41   Train only conv4 of the ResNet-18 (remove conv5), freeze the previous ones
2022-01-18 17:19:47   Output dimension of the model is 16384
2022-01-18 17:19:47   Start training epoch: 00
2022-01-18 17:19:47   Cache: 0 / 5
2022-01-18 17:21:58   Epoch[00](0/5): current batch triplet loss = 0.1000, average epoch triplet loss = 0.0596
2022-01-18 17:21:58   Cache: 1 / 5
2022-01-18 17:24:08   Epoch[00](1/5): current batch triplet loss = 0.1000, average epoch triplet loss = 0.0798
2022-01-18 17:24:08   Cache: 2 / 5
2022-01-18 17:26:19   Epoch[00](2/5): current batch triplet loss = 0.1000, average epoch triplet loss = 0.0865
2022-01-18 17:26:19   Cache: 3 / 5
2022-01-18 17:28:34   Epoch[00](3/5): current batch triplet loss = 0.1000, average epoch triplet loss = 0.0899
2022-01-18 17:28:34   Cache: 4 / 5
2022-01-18 17:30:55   Epoch[00](4/5): current batch triplet loss = 0.1000, average epoch triplet loss = 0.0919
2022-01-18 17:30:55   Finished epoch 00 in 0:11:08, average epoch triplet loss = 0.0919
2022-01-18 17:30:55   Extracting database features for evaluation/testing
2022-01-18 17:31:22   Extracting queries features for evaluation/testing
2022-01-18 17:31:43   Calculating recalls
2022-01-18 17:32:06   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 0.0, R@5: 0.0, R@10: 0.0, R@20: 0.0
2022-01-18 17:32:06   Not improved: 1 / 3: best R@5 = 0.0, current R@5 = 0.0
2022-01-18 17:32:06   Start training epoch: 01
2022-01-18 17:32:06   Cache: 0 / 5
2022-01-18 17:34:29   Epoch[01](0/5): current batch triplet loss = 0.1000, average epoch triplet loss = 0.1000
2022-01-18 17:34:29   Cache: 1 / 5
2022-01-18 17:36:53   Epoch[01](1/5): current batch triplet loss = 0.1000, average epoch triplet loss = 0.1000
2022-01-18 17:36:53   Cache: 2 / 5
2022-01-18 17:37:43   
Traceback (most recent call last):
  File "/home/franzhd/Aml_project/project_vg/run_train.py", line 96, in <module>
    triplets_ds.compute_triplets(args, model)
  File "/home/franzhd/Aml_project/project_vg/datasets_ws.py", line 253, in compute_triplets
    neg_indexes = self.get_hardest_negatives_indexes(args, cache, query_features, neg_indexes)
  File "/home/franzhd/Aml_project/project_vg/datasets_ws.py", line 223, in get_hardest_negatives_indexes
    faiss_index.add(neg_features)
  File "/home/franzhd/.local/lib/python3.9/site-packages/faiss/__init__.py", line 194, in replacement_add
    self.add_c(n, swig_ptr(x))
  File "/home/franzhd/.local/lib/python3.9/site-packages/faiss/swigfaiss.py", line 1917, in add
    return _swigfaiss.IndexFlat_add(self, n, x)
KeyboardInterrupt

